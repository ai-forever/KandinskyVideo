<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Text-to-video generation model that demonstrates high-quality dynamics, appearance, and text alignment.">
  <meta name="keywords" content="Text-to-Video, Kandinsky Video">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Kandinsky Video</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/video-camera.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Kandinsky Video </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Vladimir Arkhipkin</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Zein Shaheen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Viacheslav Vasilev</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Elizaveta Dakhova</a><sup>3</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Andrey Kuznetsov</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://ai-forever.github.io/kandinsky-video/">Denis Dimitrov</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sber AI&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>MIPT&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block"><sup>3</sup>AIRI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2311.13073.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.13073"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ai-forever/KandinskyVideo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="columns is-centered has-text-centered">
    <div class="hero-body">
      <div class="container">
      <!-- <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/meduza.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fireplace.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/explosion.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/road.mp4"
                    type="video/mp4">
          </video>
        </div>  
      </div>
    </div> -->
    	    <img src="./static/images/title.JPG"
    	    class="interpolation-image"
    	    alt="Interpolate start reference image."/>
            <p class="subtitle has-text-centered">
              <b>Kandinsky Video</b> is a text-to-video generation model, which is based on the <a href="https://arxiv.org/abs/2311.13073"><b>FusionFrames</b></a> architecture and <a href="https://ai-forever.github.io/Kandinsky-3/"><b>Kandinsky 3.0</b></a> text-to-image model, consisting of two main stages - keyframe generation and interpolation.
              Our approach for temporal conditioning allows us to generate videos with high-quality appearance, smoothness and dynamics.
            </p>
        </div>
      </div>
  </div>
</section>

<!-- FusionFrames is a text-to-video generation model consisting of two main stages - keyframe generation and interpolation.  -->
<!-- Our approach for temporal conditioning allows us to generate videos with high-quality appearance, smoothness and dynamics. -->
<!--  -->

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Multimedia generation approaches occupy a prominent place in artificial intelligence research. Text-to-image models achieved high-quality results over the last few years. However, video synthesis methods recently started to develop. This paper presents a new two-stage latent diffusion
text-to-video generation architecture based on the text-to-image diffusion model. The first stage concerns keyframes synthesis to figure the storyline of a video, while the second one is devoted to interpolation frames generation to make movements of the scene and objects smooth. We compare
several temporal conditioning approaches for keyframes generation. The results show the advantage of using separate temporal blocks over temporal layers in terms of metrics reflecting video generation quality aspects and human preference. The design of our interpolation model significantly reduces computational costs compared to other masked frame interpolation approaches. Furthermore, we evaluate different configurations of MoVQ-based video decoding scheme to improve consistency and achieve higher PSNR, SSIM, MSE, and LPIPS scores. Finally, we compare our pipeline with existing solutions and achieve top-2 scores overall and top-1 among open-source solutions: CLIPSIM = 0.2976 and FVD = 433.054. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Overall Pipeline</h2>
        <div class="content has-text-justified">
          <img src="./static/images/pipeline.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            The encoded text prompt enters the U-Net keyframe generation model with temporal layers or blocks, and then the sampled latent keyframes are  sent to the latent interpolation model in such a way as to predict three interpolation frames between two keyframes. A temporal MoVQ-GAN decoder is used to get the final video result.
          </p>
        </div>
      </div>    
    </div>
    <!--/ Matting. -->

      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Keyframes Generation with Temporal Conditioning </h2>
          <div class="content has-text-justified">
            <img src="./static/images/temporal_layers_blocks.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            We examined two approaches of temporal components use in pretrained architecture of T2I U-Net from Kandinsky 3.0 â€“ the traditional approach of mixing spatial and temporal layers in one block (<b>left</b>) and our approach of allocating a separate temporal block (<b>middle</b>). 
            All layers indicated in gray are not trained in T2V architectures and are initialized with the weights of the T2I Kandinsky 3.0 model. 
            NA and N in the left corner of all layers correspond to the presence of prenormalization layers with and without activation, respectively. 
            For different types of blocks we implemented different types of temporal attention and temporal convolution layers, (<b>left</b>). 
            We also implement different types of temporal conditioning. One of them is simple conditioning when pixel see only itself value in different moments of type (1D layers). 
            In 3D layers pixels can see the values of its neighbors also in different moments of time (<b>right</b>).
          </p>
          </div>
        </div>    
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Video Frame Interpolation</h2>
          <div class="content has-text-justified">
            <img src="./static/images/interpolation_ours.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          <p>
            A summary of the primary changes made to the T2I architecture includes: 
            (i) The input convolution now accepts three noisy latent inputs (interpolated frames) and two conditioning latent inputs (keyframes). 
            (ii) The output convolution predicts three denoised latents.
             (iii) Temporal convolutions have been introduced after each spatial convolution.

          </p>
          </div>
        </div>    
      </div>
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results for temporal conditioning</h2>
        <div class="content has-text-justified">
        
        <img src="./static/images/panda_generations.jpg"
            class="interpolation-image"
            alt="Interpolate start reference image."/>
          
        <p>
          We propose our approach for temporal conditioning based on separate temporal blocks. 
          We compared three types of temporal blocks with temporal layers, which were commonly used in previous works, and gained the advantage of our approach in terms of frame quality, text alignment and temporal consistency.
        </p>
        
        <div class="container">
          <h3>Comparison</h3>
          <table class="center">
              <tbody><tr<td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_1d.gif" raw="true"></td>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_3dattn.gif"></td>
                <td><img src="./static/videos/Meerkat_conv_attn_blocks_3dconv.gif"></td>              
                <td><img src="./static/videos/Meerkat_conv_attn_layers_1d.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">Conv1dAttn1dBlocks</td>
                <td width="25%" style="text-align:center;">Conv1dAttn3dBlocks</td>
                <td width="25%" style="text-align:center;">Conv3dAttn1dBlocks</td>
                <td width="25%" style="text-align:center;">Conv1dAttn1dLayers</td>
              </tr>
            </tbody>
            </table>
        </div>
        
        </div>
      </div>    
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <div class="content has-text-justified">  
            <h2 class="title is-3">Other results</h2>
            <table class="center">
              <tbody><tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/A car moving on the road from the sea to the mountains.gif" raw="true"></td>
                <td><img src="./static/videos/A red car drifting, 4k video.gif"></td>
                <td><img src="./static/videos/chemistry laboratory, chemical explosion, 4k.gif"></td>              
                <td><img src="./static/videos/Erupting volcano_ raw power, molten lava, and the forces of the Earth.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"A car moving on the road from the sea to the mountains"</td>
                <td width="25%" style="text-align:center;">"A red car drifting, 4k video"</td>
                <td width="25%" style="text-align:center;">"Chemistry laboratory, chemical explosion, 4k"</td>
                <td width="25%" style="text-align:center;">"Erupting volcano raw power, molten lava, and the forces of the Earth"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/luminescent jellyfish swims underwater, neon, 4k.gif" raw="true"></td>
                <td><img src="./static/videos/Majestic waterfalls in a lush rainforest_ power, mist, and biodiversity.gif"></td>
                <td><img src="./static/videos/white ghost flies through a night clearing, 4k.gif"></td>              
                <td><img src="./static/videos/Wildlife migration_ herds on the move, crossing landscapes in harmony.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Luminescent jellyfish swims underwater, neon, 4k"</td>
                <td width="25%" style="text-align:center;">"Majestic waterfalls in a lush rainforest power, mist, and biodiversity"</td>
                <td width="25%" style="text-align:center;">"White ghost flies through a night clearing, 4k"</td>
                <td width="25%" style="text-align:center;">"Wildlife migration herds on the move, crossing landscapes in harmony"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Majestic humpback whale breaching_ power, grace, and ocean spectacle.gif" raw="true"></td>
                <td><img src="./static/videos/Evoke the sense of wonder in a time-lapse journey through changing seasons.gif"></td>
                <td><img src="./static/videos/Explore the fascinating world of underwater creatures in a visually stunning sequence.gif"></td>              
                <td><img src="./static/videos/Polar ice caps_ the pristine wilderness of the Arctic and Antarctic.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Majestic humpback whale breaching power, grace, and ocean spectacle"</td>
                <td width="25%" style="text-align:center;">"Evoke the sense of wonder in a time-lapse journey through changing seasons"</td>
                <td width="25%" style="text-align:center;">"Explore the fascinating world of underwater creatures in a visually stunning sequence"</td>
                <td width="25%" style="text-align:center;">"Polar ice caps the pristine wilderness of the Arctic and Antarctic"</td>
              </tr>
              <tr><td></td><td></td><td></td><td></td></tr>
              <tr>
                <td><img src="./static/videos/Rolling waves on a sandy beach_ relaxation, rhythm, and coastal beauty.gif" raw="true"></td>
                <td><img src="./static/videos/Sloth in slow motion_ deliberate movements, relaxation, and arboreal life.gif"></td>
                <td><img src="./static/videos/Sunrise over a tranquil mountain landscape_ colors, serenity, and awakening.gif"></td>              
                <td><img src="./static/videos/Craft a heartwarming narrative showcasing the bond between a human and their loyal pet companion.gif"></td>
              </tr>
              <tr>
                <td width="25%" style="text-align:center;">"Rolling waves on a sandy beach relaxation, rhythm, and coastal beauty"</td>
                <td width="25%" style="text-align:center;">"Sloth in slow motion deliberate movements, relaxation, and arboreal life"</td>
                <td width="25%" style="text-align:center;">"Sunrise over a tranquil mountain landscape colors, serenity, and awakening"</td>
                <td width="25%" style="text-align:center;">"Craft a heartwarming narrative showcasing the bond between a human and their loyal pet companion"</td>
              </tr>
            </tbody></table>
        </div>    
      </div>
    </div>
  </div>

<hr>
<section class="section" id="Acknowledgment">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgment</h2>

    The authors express great gratitude to Igor Pavlov, Anastasia Lysenko and Sergey Markov for their contribution in collecting and processing video data,
     thanks to which this study became possible and Andrei Filatov for building the site.


  </div></section>

</section>
<hr>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{arkhipkin2023fusionframes,
  title     = {FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline},
  author    = {Arkhipkin, Vladimir and Shaheen, Zein and Vasilev, Viacheslav and Dakhova, Elizaveta and Kuznetsov, Andrey and Dimitrov, Denis},
  journal   = {arXiv preprint arXiv:2311.13073},
  year      = {2023}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
